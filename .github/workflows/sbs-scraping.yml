name: Scraping SBS Diario

on:
  schedule:
    - cron: '0 5 * * *'  # Ejecuta todos los días a las 00:00 hora Perú (5:00 UTC)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout del código
        uses: actions/checkout@v4

      - name: Configurar Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ejecutar scraper headless con Xvfb
        env:
          DISPLAY: :99
        run: |
          sudo chmod 1777 /dev/shm
          Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
          python sbs_scraping.py

      - name: Commit y push de carpeta generada
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Configura URL remota con token para autenticar el push
          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git

          git pull --rebase origin main

          git add SBS-RETASAS-*
          if git diff --cached --quiet; then
            echo "No hay cambios para commitear"
          else
            git commit -m "Actualización automática de datos SBS $(date +'%d-%m-%Y %H:%M')"
            git push origin main
          fi

