name: Scraping SBS Diario

on:
  schedule:
    - cron: '0 5 * * *'  # Ejecutar cada día a las 00:00 hora Perú (5:00 UTC)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout del código
        uses: actions/checkout@v4

      - name: Configurar Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ejecutar scraper en headless
        env:
          DISPLAY: :99
        run: |
          sudo chmod 1777 /dev/shm
          Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
          python sbs_scraping.py

      - name: Subir resultados como artifact
        uses: actions/upload-artifact@v4
        with:
          name: datos-sbs-${{ github.run_number }}
          path: SBS-RETASAS-*
          if-no-files-found: error

      - name: Commit y Push de resultados
        if: success()
        run: |
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"
          git pull --rebase
          git add SBS-RETASAS-*
          if git diff-index --quiet HEAD --; then
            echo "No hay cambios para commitear"
          else
            git commit -m "Actualización SBS ${{ github.run_number }}"
            git push origin HEAD:${{ github.ref }}
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
