name: Scraping SBS Diario

on:
  schedule:
    # 12am Hora Perú = 5am UTC (UTC-5)
    - cron: '0 5 * * *'
  workflow_dispatch:  # Para ejecución manual

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout del código
      uses: actions/checkout@v4

    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Instalar Chrome
      uses: nanasess/setup-chromedriver@v1
      with:
        chrome-version: 'latest'
        chromedriver-version: 'latest'

    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Ejecutar scraping
      env:
        DISPLAY: :99
      run: |
        sudo chmod 1777 /dev/shm
        Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
        python sbs_scraping.py

    - name: Subir resultados como artifact
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: datos-sbs-${{ github.run_id }}
        path: SBS-RETASAS-*/
        
