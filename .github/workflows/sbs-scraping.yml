name: Scraping SBS Diario

on:
  schedule:
    - cron: '0 5 * * *'  # 12am Hora Perú (5am UTC)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout del código
      uses: actions/checkout@v4

    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Instalar Chrome y Chromedriver
      uses: nanasess/setup-chromedriver@v1
      with:
        chrome-version: 'latest-stable'
        chromedriver-version: 'latest-stable'

    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Ejecutar scraping
      env:
        DISPLAY: :99
      run: |
        sudo chmod 1777 /dev/shm
        Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &
        python sbs_scraping.py

    - name: Subir resultados como artifact
      uses: actions/upload-artifact@v4  # Versión actualizada
      with:
        name: datos-sbs-${{ github.run_number }}
        path: |
          SBS-RETASAS-*
          !SBS-RETASAS-*/**/*.png  # Excluye screenshots de error
        if-no-files-found: error  # Falla si no hay archivos

    - name: Commit y Push de resultados
      if: success()
      run: |
        git config --global user.email "actions@github.com"
        git config --global user.name "GitHub Actions"
        git pull --rebase
        git add SBS-RETASAS-*
        if git diff-index --quiet HEAD --; then
          echo "No hay cambios para commitear"
        else
          git commit -m "Actualización SBS ${{ steps.scrape.outputs.date }}"
          git push origin HEAD:${{ github.ref }}
        fi
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}